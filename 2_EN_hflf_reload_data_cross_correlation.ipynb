{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------HH1 & HH2---------------------------------#\n",
    "#----------------Do cross correlation----------------------#\n",
    "#----------envelope cross-crrelation method----------------#\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "client = Client(\"USGS\")\n",
    "from obspy import UTCDateTime\n",
    "import numpy as np\n",
    "from obspy.geodetics import locations2degrees\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "from obspy.geodetics import degrees2kilometers\n",
    "from obspy import read\n",
    "\n",
    "import scipy\n",
    "import scipy.signal as scisignal\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.taup import TauPyModel\n",
    "model = TauPyModel(model=\"iasp91\")\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "from obspy.signal.trigger import classic_sta_lta\n",
    "from obspy.signal.trigger import plot_trigger\n",
    "\n",
    "import os\n",
    "# import geopy.distance\n",
    "import glob\n",
    "import obspy.signal.filter\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import pickle\n",
    "import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------load OBS data--------------------#\n",
    "obs = pd.read_csv('Seismometer_station',sep ='   ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------A function to calculate segment and cumulate length--------#\n",
    "def seg_cum_function(data):\n",
    "    avg = np.mean(data)\n",
    "    data_box = np.zeros(3*60)\n",
    "    data_box[data>avg] = 1\n",
    "    cum_len = np.where(data>avg)\n",
    "    seg = 0\n",
    "    for iseg in range(3*60-1):\n",
    "        if data_box[iseg]==0 and data_box[iseg+1]==1:\n",
    "            seg += 1   \n",
    "    return seg,cum_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------A function to remove zero valus---------------------##\n",
    "def zeromean(data):\n",
    "    for iw in range(len(data)):\n",
    "        if data[iw] == 0.0:\n",
    "            data[iw] = np.nan\n",
    "    return np.nanmean(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------- load two earthquake catalogs ----------------------##\n",
    "eqcat = pd.read_csv('located_catalog_scak400km',sep =' ')\n",
    "equsgs = pd.read_csv('usgs_20180501_20190831.csv')\n",
    "\n",
    "datetime_eq = [datetime.datetime.strptime(itime,'%Y-%m-%dT%H:%M:%S.%f') for itime in eqcat['Time']]\n",
    "datetime_usgs = [datetime.datetime.strptime(itime,'%Y-%m-%dT%H:%M:%S.%fZ') for itime in equsgs['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Direc = '2018-**-**'\n",
    "datetime0 = datetime.datetime.strptime(Direc,'%Y-%m-%d')\n",
    "## set up a day\n",
    "l1 = 2; l2 = 8; h1 = 10; h2 = 16;\n",
    "for iday in range(***):\n",
    "    datetime1 = datetime0 + datetime.timedelta(days = iday)\n",
    "    Direc = datetime.datetime.strftime(datetime1,'%Y-%m-%d')\n",
    "    print(Direc)\n",
    "    \n",
    "## obtain data    \n",
    "    cha = 'HH1'\n",
    "    sta_name = glob.glob(Direc + '/*_HH2_180s_hf_'+str(h1)+'-'+str(h2)+'.npy')\n",
    "    sta_name2 = [x.split(\"/\")[1].split(\"_\")[0] for x in sta_name]\n",
    "    # from collections import defaultdict\n",
    "    data_HH1_lf = dict.fromkeys(sta_name2)\n",
    "    data_HH1_hf = dict.fromkeys(sta_name2)\n",
    " \n",
    "    for ista in range(len(sta_name2)):\n",
    "        with open(Direc + '/' + sta_name2[ista] +'_'+ cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "            data_HH1_lf[sta_name2[ista]]=np.load(f)\n",
    "        with open(Direc + '/' + sta_name2[ista] +'_'+ cha + '_180s_hf_'+str(h1)+'-'+str(h2)+'.npy','rb') as f:\n",
    "            data_HH1_hf[sta_name2[ista]]=np.load(f)            \n",
    "    with open(Direc + '/EP22_' + cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "        data_HH1_rf1 = np.load(f)  \n",
    "    with open(Direc + '/WD53_' + cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "        data_HH1_rf2 = np.load(f)  \n",
    "    with open(Direc + '/LT20_' + cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "        data_HH1_rf3 = np.load(f)  \n",
    "    with open(Direc + '/WD67_' + cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "        data_HH1_rf4 = np.load(f) \n",
    "        \n",
    "    cha = 'HH2'\n",
    "    data_HH2_lf = dict.fromkeys(sta_name2)\n",
    "    data_HH2_hf = dict.fromkeys(sta_name2)\n",
    "    for ista in range(len(sta_name2)):\n",
    "        with open(Direc + '/' + sta_name2[ista] +'_'+ cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "            data_HH2_lf[sta_name2[ista]]=np.load(f)\n",
    "        with open(Direc + '/' + sta_name2[ista] +'_'+ cha + '_180s_hf_'+str(h1)+'-'+str(h2)+'.npy','rb') as f:\n",
    "            data_HH2_hf[sta_name2[ista]]=np.load(f)            \n",
    "    with open(Direc + '/EP22_' + cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "        data_HH2_rf1 = np.load(f) \n",
    "    with open(Direc + '/WD53_' + cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "        data_HH2_rf2 = np.load(f) \n",
    "    with open(Direc + '/LT20_' + cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "        data_HH2_rf3 = np.load(f) \n",
    "    with open(Direc + '/WD67_' + cha + '_180s_lf_'+str(l1)+'-'+str(l2)+'.npy','rb') as f:\n",
    "        data_HH2_rf4 = np.load(f)         \n",
    "        \n",
    "## Calculate Cross-correlation, 959: the length of 1 day seismic data\n",
    "    shift_day_H1_lf = dict.fromkeys(range(959))\n",
    "    shift_day_H2_lf = dict.fromkeys(range(959))\n",
    "    cc_day_lf = dict.fromkeys(range(959))\n",
    "    cc_day_hf = dict.fromkeys(range(959))\n",
    "    cc_day_rf1 = dict.fromkeys(range(959))\n",
    "    cc_day_rf2 = dict.fromkeys(range(959))\n",
    "    cc_day_rf3 = dict.fromkeys(range(959))\n",
    "    cc_day_rf4 = dict.fromkeys(range(959))\n",
    "    \n",
    "    for istep in range(959):\n",
    "        cc_matrix_lf = np.zeros((len(sta_name2),len(sta_name2)))\n",
    "        cc_matrix_hf = np.zeros((len(sta_name2),len(sta_name2)))\n",
    "        cc_matrix_rf1 = np.zeros((len(sta_name2),1))\n",
    "        cc_matrix_rf2 = np.zeros((len(sta_name2),1))\n",
    "        cc_matrix_rf3 = np.zeros((len(sta_name2),1))\n",
    "        cc_matrix_rf4 = np.zeros((len(sta_name2),1))\n",
    "        \n",
    "        shift_matrix_H1_lf = np.zeros((len(sta_name2),len(sta_name2)))\n",
    "        shift_matrix_H2_lf = np.zeros((len(sta_name2),len(sta_name2)))\n",
    "\n",
    "        for ista1 in range(len(sta_name2)):     \n",
    "            dataH1_lf = data_HH1_lf[sta_name2[ista1]][:,istep]\n",
    "            seg1,cum_len1 = seg_cum_function(dataH1_lf)\n",
    "            dataH1_hf = data_HH1_hf[sta_name2[ista1]][:,istep]\n",
    "            seg_hf1,cum_len_hf1 = seg_cum_function(dataH1_hf)\n",
    "            \n",
    "            dataH2_lf = data_HH2_lf[sta_name2[ista1]][:,istep]\n",
    "            seg2,cum_len2 = seg_cum_function(dataH2_lf)\n",
    "            dataH2_hf = data_HH2_hf[sta_name2[ista1]][:,istep] \n",
    "            seg_hf2,cum_len_hf2 = seg_cum_function(dataH2_hf)\n",
    "            \n",
    "            if ((np.std(dataH1_lf)!=0.0 or np.std(dataH2_lf)!=0.0) and \n",
    "                (seg1>10 or seg2>10 or (len(cum_len1[0])/180)>0.3 or (len(cum_len2[0])/180)>0.3)):    \n",
    "                \n",
    "    ## reference station EP22\n",
    "                seg_rf1,cum_len_rf1 = seg_cum_function(data_HH1_rf1[:,istep])\n",
    "                seg_rf2,cum_len_rf2 = seg_cum_function(data_HH2_rf1[:,istep])\n",
    "                if (seg_rf1>10 or seg_rf2>10 or (len(cum_len_rf1[0])/180)>0.3 or (len(cum_len_rf2[0])/180)>0.3): \n",
    "                    cc_rf1 = obspy.signal.cross_correlation.correlate(dataH1_lf,data_HH1_rf1[:,istep],90,\n",
    "                                                                   demean=True,normalize='naive')                        \n",
    "                    shift_rf1,value_rf1 = obspy.signal.cross_correlation.xcorr_max(cc_rf1,abs_max=False) \n",
    "\n",
    "                    cc_rf2 = obspy.signal.cross_correlation.correlate(dataH2_lf,data_HH2_rf1[:,istep],90,\n",
    "                                                                   demean=True,normalize='naive')                        \n",
    "                    shift_rf2,value_rf2 = obspy.signal.cross_correlation.xcorr_max(cc_rf2,abs_max=False)\n",
    "                    cc_matrix_rf1[ista1] = zeromean([value_rf1,value_rf2])\n",
    "\n",
    "    ## reference station WD53 \n",
    "                seg_rf3,cum_len_rf3 = seg_cum_function(data_HH1_rf2[:,istep])\n",
    "                seg_rf4,cum_len_rf4 = seg_cum_function(data_HH2_rf2[:,istep])\n",
    "                if (seg_rf3>10 or seg_rf4>10 or (len(cum_len_rf3[0])/180)>0.3 or (len(cum_len_rf4[0])/180)>0.3):     \n",
    "                    cc_rf3 = obspy.signal.cross_correlation.correlate(dataH1_lf,data_HH1_rf2[:,istep],90,\n",
    "                                                                   demean=True,normalize='naive')                        \n",
    "                    shift_rf3,value_rf3 = obspy.signal.cross_correlation.xcorr_max(cc_rf3,abs_max=False) \n",
    "\n",
    "                    cc_rf4 = obspy.signal.cross_correlation.correlate(dataH2_lf,data_HH2_rf2[:,istep],90,\n",
    "                                                                   demean=True,normalize='naive')                        \n",
    "                    shift_rf4,value_rf4 = obspy.signal.cross_correlation.xcorr_max(cc_rf4,abs_max=False)\n",
    "                    cc_matrix_rf2[ista1] = zeromean([value_rf3,value_rf4])\n",
    "\n",
    "    ## reference station LT20\n",
    "                seg_rf5,cum_len_rf5 = seg_cum_function(data_HH1_rf3[:,istep])\n",
    "                seg_rf6,cum_len_rf6 = seg_cum_function(data_HH2_rf3[:,istep])\n",
    "                if (seg_rf5>10 or seg_rf6>10 or (len(cum_len_rf5[0])/180)>0.3 or (len(cum_len_rf6[0])/180)>0.3):      \n",
    "                    cc_rf5 = obspy.signal.cross_correlation.correlate(dataH1_lf,data_HH1_rf3[:,istep],90,\n",
    "                                                                   demean=True,normalize='naive')                        \n",
    "                    shift_rf5,value_rf5 = obspy.signal.cross_correlation.xcorr_max(cc_rf5,abs_max=False) \n",
    "\n",
    "                    cc_rf6 = obspy.signal.cross_correlation.correlate(dataH2_lf,data_HH2_rf3[:,istep],90,\n",
    "                                                                   demean=True,normalize='naive')                        \n",
    "                    shift_rf6,value_rf6 = obspy.signal.cross_correlation.xcorr_max(cc_rf6,abs_max=False)\n",
    "                    cc_matrix_rf3[ista1] = zeromean([value_rf5,value_rf6])\n",
    "\n",
    "    ## reference station WD67     \n",
    "                seg_rf7,cum_len_rf7 = seg_cum_function(data_HH1_rf4[:,istep])\n",
    "                seg_rf8,cum_len_rf8 = seg_cum_function(data_HH2_rf4[:,istep])\n",
    "                if (seg_rf7>10 or seg_rf8>10 or (len(cum_len_rf7[0])/180)>0.3 or (len(cum_len_rf8[0])/180)>0.3):  \n",
    "                    cc_rf7 = obspy.signal.cross_correlation.correlate(dataH1_lf,data_HH1_rf4[:,istep],90,\n",
    "                                                                   demean=True,normalize='naive')                        \n",
    "                    shift_rf7,value_rf7 = obspy.signal.cross_correlation.xcorr_max(cc_rf7,abs_max=False) \n",
    "\n",
    "                    cc_rf8 = obspy.signal.cross_correlation.correlate(dataH2_lf,data_HH2_rf4[:,istep],90,\n",
    "                                                                   demean=True,normalize='naive')                        \n",
    "                    shift_rf8,value_rf8 = obspy.signal.cross_correlation.xcorr_max(cc_rf8,abs_max=False)\n",
    "                    cc_matrix_rf4[ista1] = zeromean([value_rf7,value_rf8])         \n",
    "            \n",
    "                \n",
    "                for ista2 in range(ista1+1,len(sta_name2)):\n",
    "                    dataH3_lf = data_HH1_lf[sta_name2[ista2]][:,istep]\n",
    "                    seg3,cum_len3 = seg_cum_function(dataH3_lf)\n",
    "                    dataH3_hf = data_HH1_hf[sta_name2[ista2]][:,istep]\n",
    "                    seg_hf3,cum_len_hf3 = seg_cum_function(dataH3_hf)\n",
    "                    \n",
    "                    dataH4_lf = data_HH2_lf[sta_name2[ista2]][:,istep]\n",
    "                    seg4,cum_len4 = seg_cum_function(dataH4_lf) \n",
    "                    dataH4_hf = data_HH2_hf[sta_name2[ista2]][:,istep]\n",
    "                    seg_hf4,cum_len_hf4 = seg_cum_function(dataH4_hf)\n",
    "                    \n",
    "                    if ((np.std(dataH3_lf)!=0.0 or np.std(dataH4_lf)!=0.0) and \n",
    "                        (seg3>10 or seg4>10 or (len(cum_len3[0])/180)>0.3 or (len(cum_len4[0])/180)>0.3)):\n",
    "                        \n",
    "    ## cc values & shifts: low pass filterred data\n",
    "                        cc1 = obspy.signal.cross_correlation.correlate(dataH1_lf,dataH3_lf,20,\n",
    "                                                                       demean=True,normalize='naive')                        \n",
    "                        shift1,value1 = obspy.signal.cross_correlation.xcorr_max(cc1,abs_max=False)                        \n",
    "                        shift_matrix_H1_lf[ista1,ista2] = shift1\n",
    "                        cc2 = obspy.signal.cross_correlation.correlate(dataH2_lf,dataH4_lf,20,\n",
    "                                                                       demean=True,normalize='naive')                        \n",
    "                        shift2,value2 = obspy.signal.cross_correlation.xcorr_max(cc2,abs_max=False)                        \n",
    "                        shift_matrix_H2_lf[ista1,ista2] = shift2  \n",
    "                        cc_matrix_lf[ista1,ista2] = max([value1,value2])\n",
    "                        \n",
    "                    if ((np.std(dataH3_lf)!=0.0 or np.std(dataH4_lf)!=0.0) and \n",
    "                        (seg_hf3>10 or seg_hf4>10 or (len(cum_len_hf3[0])/180)>0.3 or (len(cum_len_hf4[0])/180)>0.3) and\n",
    "                        (seg_hf1>10 or seg_hf2>10 or (len(cum_len_hf1[0])/180)>0.3 or (len(cum_len_hf2[0])/180)>0.3)):                        \n",
    "    ## cc values & shifts: high pass filterred data      \n",
    "    \n",
    "                        cc3 = obspy.signal.cross_correlation.correlate(dataH1_hf,dataH3_hf,20,\n",
    "                                                                       demean=True,normalize='naive')                        \n",
    "                        shift3,value3 = obspy.signal.cross_correlation.xcorr_max(cc3,abs_max=False)                        \n",
    "                        cc4 = obspy.signal.cross_correlation.correlate(dataH2_hf,dataH4_hf,20,\n",
    "                                                                       demean=True,normalize='naive')                        \n",
    "                        shift4,value4 = obspy.signal.cross_correlation.xcorr_max(cc4,abs_max=False)                      \n",
    "                        cc_matrix_hf[ista1,ista2] = zeromean([value3,value4])     \n",
    "                    \n",
    "        shift_day_H1_lf[istep] = shift_matrix_H1_lf; \n",
    "        shift_day_H2_lf[istep] = shift_matrix_H2_lf;\n",
    "        cc_day_lf[istep] = cc_matrix_lf;   \n",
    "        cc_day_hf[istep] = cc_matrix_hf; \n",
    "        cc_day_rf1[istep] = cc_matrix_rf1; cc_day_rf2[istep] = cc_matrix_rf2; \n",
    "        cc_day_rf3[istep] = cc_matrix_rf3; cc_day_rf4[istep] = cc_matrix_rf4; \n",
    "\n",
    "# save data\n",
    "    with open(Direc + '/cc_day_lf_'+str(l1)+'-'+str(l2)+'_'+str(h1)+'-'+str(h2)+'.pkl','wb') as f1:\n",
    "        pickle.dump(cc_day_lf,f1)\n",
    "    with open(Direc + '/cc_day_hf_'+str(l1)+'-'+str(l2)+'_'+str(h1)+'-'+str(h2)+'.pkl',\"wb\") as f1:\n",
    "        pickle.dump(cc_day_hf,f1)\n",
    "    with open(Direc + '/cc_day_rf_EP22_'+str(l1)+'-'+str(l2)+'.pkl',\"wb\") as f1:\n",
    "        pickle.dump(cc_day_rf1,f1)\n",
    "    with open(Direc + '/cc_day_rf_WD53_'+str(l1)+'-'+str(l2)+'.pkl',\"wb\") as f1:\n",
    "        pickle.dump(cc_day_rf2,f1)\n",
    "    with open(Direc + '/cc_day_rf_LT20_'+str(l1)+'-'+str(l2)+'.pkl',\"wb\") as f1:\n",
    "        pickle.dump(cc_day_rf3,f1)\n",
    "    with open(Direc + '/cc_day_rf_WD67_'+str(l1)+'-'+str(l2)+'.pkl',\"wb\") as f1:\n",
    "        pickle.dump(cc_day_rf4,f1)\n",
    "        \n",
    "    with open(Direc + \"/shift_day_H1_lf_2-8_10-16.pkl\",\"wb\") as f1:\n",
    "        pickle.dump(shift_day_H1_lf,f1)\n",
    "    with open(Direc + \"/shift_day_H2_lf_2-8_10-16.pkl\",\"wb\") as f1:\n",
    "        pickle.dump(shift_day_H2_lf,f1)    \n",
    "    with open(Direc + '/station_name.npy','wb') as f:\n",
    "        np.save(f,sta_name2)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
